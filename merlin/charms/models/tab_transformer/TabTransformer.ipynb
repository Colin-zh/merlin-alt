{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b30afae",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "论文原文：[《TabTransformer: Tabular Data Modeling Using Contextual Embeddings》](https://arxiv.org/abs/2012.06678)\n",
    "\n",
    "参考学习地址：[[73] TabTransformer: 用Transformer处理表格型数据](https://zhuanlan.zhihu.com/p/683616720)\n",
    "\n",
    "代码库：https://github.com/lucidrains/tab-transformer-pytorch\n",
    "\n",
    "Tab-Transformer重点关注于类别型特征，通过column-embedding后接多层Transformer处理，对于连续型变量直接Layer Norm，两者Concat后作为MLP输入。\n",
    "\n",
    "<img style=\"display: block; margin: 0 auto;\" src=\"../../../assets/images/tab-transformer.png\" width = \"400\" height = \"600\" alt=\"TAB-Transformer\" align=center />\n",
    "\n",
    "# 维度变化\n",
    "另特征输入 $x \\equiv \\{x_{cat}, x_{cont}\\}$，其中$x_{cat} \\equiv \\{x_1, x_2, ..., x_m\\}$（$x_i$代表对应位置的类别特征, i.e. field），$x_{cont}\\in \\R^c$，embedding size设为d，transformer不改变维度，输出为$\\{h_1, ..., h_m\\}, h_i\\in \\R^d$。\n",
    "\n",
    "所以可以看到离散型特征对应transformer的输出维度为 $m\\times d$，而连续型特征对应layer norm输出维度为 $c$。Tab-Transformer把这两个输出展平后concat，最终输入MLP的维度为 ${d\\times m + c}$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
