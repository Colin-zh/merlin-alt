{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/lucidrains/tab-transformer-pytorch.git\n",
        "\n",
        "![Tab-vs-FT](https://github.com/lucidrains/tab-transformer-pytorch/blob/main/tab-vs-ft.png?raw=true)"
      ],
      "metadata": {
        "id": "RGTa5OcYYcue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyper-connections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wA_Tx8ZkpaOk",
        "outputId": "6cebf272-ef5f-4017-8d89-aac9de9a05ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyper-connections in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from hyper-connections) (0.8.1)\n",
            "Requirement already satisfied: torch>=2.3 in /usr/local/lib/python3.12/dist-packages (from hyper-connections) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->hyper-connections) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3->hyper-connections) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3->hyper-connections) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "from hyper_connections import HyperConnections"
      ],
      "metadata": {
        "id": "D-xVaJviZRT-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gates = x.chunk(2, dim=-1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, mult = 4, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mult * 2),\n",
        "            GEGLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim * mult, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "ICBdkDLTacdw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tab Transformer\n",
        "\n",
        "![Tab](https://github.com/lucidrains/tab-transformer-pytorch/blob/main/tab.png?raw=true)"
      ],
      "metadata": {
        "id": "MxkSdVJiZBJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        heads = 8,\n",
        "        dim_head = 16,\n",
        "        dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.heads\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
        "        sim = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "\n",
        "        attn = sim.softmax(dim = -1)\n",
        "        dropped_attn = self.dropout(attn)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', dropped_attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
        "        return self.to_out(out), attn\n",
        "\n",
        "# transformer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        depth,\n",
        "        heads,\n",
        "        dim_head,\n",
        "        attn_dropout,\n",
        "        ff_dropout,\n",
        "        num_residual_streams = 4\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        init_hyper_conn, self.expand_streams, self.reduce_streams = HyperConnections.get_init_and_expand_reduce_stream_functions(num_residual_streams, disable = num_residual_streams == 1)\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                init_hyper_conn(dim = dim, branch = PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout))),\n",
        "                init_hyper_conn(dim = dim, branch = PreNorm(dim, FeedForward(dim, dropout = ff_dropout))),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, return_attn = False):\n",
        "        post_softmax_attns = []\n",
        "\n",
        "        x = self.expand_streams(x)\n",
        "\n",
        "        for attn, ff in self.layers:\n",
        "            x, post_softmax_attn = attn(x)\n",
        "            post_softmax_attns.append(post_softmax_attn)\n",
        "\n",
        "            x = ff(x)\n",
        "\n",
        "        x = self.reduce_streams(x)\n",
        "\n",
        "        if not return_attn:\n",
        "            return x\n",
        "\n",
        "        return x, torch.stack(post_softmax_attns)\n",
        "# mlp\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dims, act = None):\n",
        "        super().__init__()\n",
        "        dims_pairs = list(zip(dims[:-1], dims[1:]))\n",
        "        layers = []\n",
        "        for ind, (dim_in, dim_out) in enumerate(dims_pairs):\n",
        "            is_last = ind >= (len(dims_pairs) - 1)\n",
        "            linear = nn.Linear(dim_in, dim_out)\n",
        "            layers.append(linear)\n",
        "\n",
        "            if is_last:\n",
        "                continue\n",
        "\n",
        "            act = default(act, nn.ReLU())\n",
        "            layers.append(act)\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n"
      ],
      "metadata": {
        "id": "28UrqeeIZAqC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TabTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        categories,\n",
        "        num_continuous,\n",
        "        dim,\n",
        "        depth,\n",
        "        heads,\n",
        "        dim_head = 16,\n",
        "        dim_out = 1,\n",
        "        mlp_hidden_mults = (4, 2),\n",
        "        mlp_act = None,\n",
        "        num_special_tokens = 2,\n",
        "        continuous_mean_std = None,\n",
        "        attn_dropout = 0.,\n",
        "        ff_dropout = 0.,\n",
        "        use_shared_categ_embed = True,\n",
        "        shared_categ_dim_divisor = 8.,   # in paper, they reserve dimension / 8 for category shared embedding\n",
        "        num_residual_streams = 4\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n",
        "        assert len(categories) + num_continuous > 0, 'input shape must not be null'\n",
        "\n",
        "        # categories related calculations\n",
        "\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "        # create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "\n",
        "        shared_embed_dim = 0 if not use_shared_categ_embed else int(dim // shared_categ_dim_divisor)\n",
        "\n",
        "        self.category_embed = nn.Embedding(total_tokens, dim - shared_embed_dim)\n",
        "\n",
        "        # take care of shared category embed\n",
        "\n",
        "        self.use_shared_categ_embed = use_shared_categ_embed\n",
        "\n",
        "        if use_shared_categ_embed:\n",
        "            self.shared_category_embed = nn.Parameter(torch.zeros(self.num_categories, shared_embed_dim))\n",
        "            nn.init.normal_(self.shared_category_embed, std = 0.02)\n",
        "\n",
        "        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
        "\n",
        "        if self.num_unique_categories > 0:\n",
        "            categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
        "            categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
        "            self.register_buffer('categories_offset', categories_offset)\n",
        "\n",
        "        # continuous\n",
        "\n",
        "        self.num_continuous = num_continuous\n",
        "\n",
        "        if self.num_continuous > 0:\n",
        "            if exists(continuous_mean_std):\n",
        "                assert continuous_mean_std.shape == (num_continuous, 2), f'continuous_mean_std must have a shape of ({num_continuous}, 2) where the last dimension contains the mean and variance respectively'\n",
        "            self.register_buffer('continuous_mean_std', continuous_mean_std)\n",
        "\n",
        "            self.norm = nn.LayerNorm(num_continuous)\n",
        "\n",
        "        # transformer\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            dim = dim,\n",
        "            depth = depth,\n",
        "            heads = heads,\n",
        "            dim_head = dim_head,\n",
        "            attn_dropout = attn_dropout,\n",
        "            ff_dropout = ff_dropout,\n",
        "            num_residual_streams = num_residual_streams\n",
        "        )\n",
        "\n",
        "        # mlp to logits\n",
        "\n",
        "        input_size = (dim * self.num_categories) + num_continuous\n",
        "\n",
        "        hidden_dimensions = [input_size * t for t in  mlp_hidden_mults]\n",
        "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
        "\n",
        "        self.mlp = MLP(all_dimensions, act = mlp_act)\n",
        "\n",
        "    def forward(self, x_categ, x_cont, return_attn = False):\n",
        "        xs = []\n",
        "\n",
        "        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n",
        "\n",
        "        if self.num_unique_categories > 0:\n",
        "            x_categ = x_categ + self.categories_offset\n",
        "\n",
        "            categ_embed = self.category_embed(x_categ)\n",
        "\n",
        "            if self.use_shared_categ_embed:\n",
        "                shared_categ_embed = repeat(self.shared_category_embed, 'n d -> b n d', b = categ_embed.shape[0])\n",
        "                categ_embed = torch.cat((categ_embed, shared_categ_embed), dim = -1)\n",
        "\n",
        "            x, attns = self.transformer(categ_embed, return_attn = True)\n",
        "\n",
        "            flat_categ = rearrange(x, 'b ... -> b (...)')\n",
        "            xs.append(flat_categ)\n",
        "\n",
        "        assert x_cont.shape[1] == self.num_continuous, f'you must pass in {self.num_continuous} values for your continuous input'\n",
        "\n",
        "        if self.num_continuous > 0:\n",
        "            if exists(self.continuous_mean_std):\n",
        "                mean, std = self.continuous_mean_std.unbind(dim = -1)\n",
        "                x_cont = (x_cont - mean) / std\n",
        "\n",
        "            normed_cont = self.norm(x_cont)\n",
        "            xs.append(normed_cont)\n",
        "\n",
        "        x = torch.cat(xs, dim = -1)\n",
        "        logits = self.mlp(x)\n",
        "\n",
        "        if not return_attn:\n",
        "            return logits\n",
        "\n",
        "        return logits, attns\n"
      ],
      "metadata": {
        "id": "yF5AdjXPa9qE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_mean_std = torch.randn(10, 2)\n",
        "\n",
        "model = TabTransformer(\n",
        "    categories = (10, 5, 6, 5, 8),      # tuple containing the number of unique values within each category\n",
        "    num_continuous = 10,                # number of continuous values\n",
        "    dim = 32,                           # dimension, paper set at 32\n",
        "    dim_out = 1,                        # binary prediction, but could be anything\n",
        "    depth = 6,                          # depth, paper recommended 6\n",
        "    heads = 8,                          # heads, paper recommends 8\n",
        "    attn_dropout = 0.1,                 # post-attention dropout\n",
        "    ff_dropout = 0.1,                   # feed forward dropout\n",
        "    mlp_hidden_mults = (4, 2),          # relative multiples of each hidden dimension of the last mlp to logits\n",
        "    mlp_act = nn.ReLU(),                # activation for final mlp, defaults to relu, but could be anything else (selu etc)\n",
        "    continuous_mean_std = cont_mean_std # (optional) - normalize the continuous values before layer norm\n",
        ")\n",
        "\n",
        "x_categ = torch.randint(0, 5, (1, 5))     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
        "x_cont = torch.randn(1, 10)               # assume continuous values are already normalized individually\n",
        "\n",
        "pred = model(x_categ, x_cont) # (1, 1)"
      ],
      "metadata": {
        "id": "ps7SsbtNa-SG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred, attn = model(x_categ, x_cont, return_attn = True)\n",
        "print(pred, attn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNJiCbI7bL9b",
        "outputId": "1c735547-4803-4ae5-aec1-bd76540f7945"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1345]], grad_fn=<AddmmBackward0>) torch.Size([6, 1, 8, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FT Transformer"
      ],
      "metadata": {
        "id": "PrmXZst4ZSvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NumericalEmbedder(nn.Module):\n",
        "    def __init__(self, dim, num_numerical_types):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "        self.biases = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = rearrange(x, \"b n -> b n 1\")\n",
        "        return x * self.weights + self.biases\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.heads\n",
        "        x = self.norm(x)\n",
        "\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        # b: batch_size, n: seq_len, h: heads, d: dim_head\n",
        "        # (b, n, h * d) -> (b, h, n, d) 等价于 q.view(b, n, h, d).transpose(1, 2)\n",
        "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h = h), (q, k, v))\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = einsum(\"b h i d, b h j d -> b h i j\", q, k)\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        dropped_attn = self.dropout(attn)\n",
        "\n",
        "        out = einsum(\"b h i j, b h j d -> b h i d\", dropped_attn, v)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\", h = h)\n",
        "        return self.to_out(out), attn\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, attn_dropout, ff_dropout, num_residual_streams=4):\n",
        "        super().__init__()\n",
        "\n",
        "        (\n",
        "            init_hyper_conn,\n",
        "            self.expand_streams,\n",
        "            self.reduce_streams\n",
        "        )= HyperConnections.get_init_and_expand_reduce_stream_functions(\n",
        "            num_residual_streams, disable = num_residual_streams == 1)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                init_hyper_conn(dim=dim, branch=Attention(dim, heads=heads, dim_head=dim_head, dropout=attn_dropout)),\n",
        "                init_hyper_conn(dim=dim, branch=FeedForward(dim, dropout=ff_dropout))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, return_attn=False):\n",
        "        post_softmax_attns = []\n",
        "\n",
        "        x = self.expand_streams(x)\n",
        "        for attn, ff in self.layers:\n",
        "            x, post_softmax_attn = attn(x)\n",
        "            post_softmax_attns.append(post_softmax_attn)\n",
        "            x = ff(x)\n",
        "        x = self.reduce_streams(x)\n",
        "\n",
        "        return x, torch.stack(post_softmax_attns) if return_attn else x"
      ],
      "metadata": {
        "id": "Rbsg-F4npzSz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FTTransformer(nn.Module):\n",
        "    def __init__(self, *, categories, num_continuous, dim, depth, heads, dim_head=16, dim_out=1, num_special_tokens=2,\n",
        "                 attn_dropout=0., ff_dropout=0., num_residual_streams=4):\n",
        "        super().__init__()\n",
        "        assert all(map(lambda n: n > 0, categories)), \"num of each category must be positive\"\n",
        "        assert len(categories) + num_continuous > 0, \"input shape must not be null\"\n",
        "\n",
        "        # categories related calculations\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "        # create category embeddings table\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "\n",
        "        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
        "        if self.num_unique_categories > 0:\n",
        "            categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
        "            categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
        "            self.register_buffer('categories_offset', categories_offset)\n",
        "\n",
        "            # categorical embedding\n",
        "            self.categorical_embeds = nn.Embedding(total_tokens, dim)\n",
        "\n",
        "        # continuous\n",
        "        self.num_continuous = num_continuous\n",
        "        if self.num_continuous > 0:\n",
        "            self.numerical_embedder = NumericalEmbedder(dim, self.num_continuous)\n",
        "\n",
        "        # cls token\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "\n",
        "        # transformer\n",
        "        self.transformer = Transformer(\n",
        "            dim = dim,\n",
        "            depth = depth,\n",
        "            heads = heads,\n",
        "            dim_head = dim_head,\n",
        "            attn_dropout = attn_dropout,\n",
        "            ff_dropout = ff_dropout,\n",
        "            num_residual_streams = num_residual_streams\n",
        "        )\n",
        "\n",
        "        # to logits\n",
        "        self.to_logits = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, dim_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_categ, x_numer, return_attn = False):\n",
        "        assert x_categ.shape[-1] == self.num_categories, \\\n",
        "            f'you must pass in {self.num_categories} values for your categories input'\n",
        "\n",
        "        xs = []\n",
        "        if self.num_unique_categories > 0:\n",
        "            x_categ = x_categ + self.categories_offset\n",
        "            x_categ = self.categorical_embeds(x_categ)\n",
        "            xs.append(x_categ)\n",
        "\n",
        "        # add numerically embedded tokens\n",
        "        if self.num_continuous > 0:\n",
        "            x_numer = self.numerical_embedder(x_numer)\n",
        "            xs.append(x_numer)\n",
        "\n",
        "        # concat categorical and numerical\n",
        "        x = torch.cat(xs, dim = 1)\n",
        "\n",
        "        # append cls tokens\n",
        "        b = x.shape[0]\n",
        "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim = 1)\n",
        "\n",
        "        # attend\n",
        "        x, attns = self.transformer(x, return_attn = True)\n",
        "\n",
        "        # get cls token\n",
        "        x = x[:, 0]\n",
        "\n",
        "        # out in the paper is linear(relu(ln(cls)))\n",
        "        logits = self.to_logits(x)\n",
        "        return (logits, attns) if return_attn else logits\n"
      ],
      "metadata": {
        "id": "a5ivHVvhzqGb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FTTransformer(\n",
        "    categories = (10, 5, 6, 5, 8),      # tuple containing the number of unique values within each category\n",
        "    num_continuous = 10,                # number of continuous values\n",
        "    dim = 32,                           # dimension, paper set at 32\n",
        "    dim_out = 1,                        # binary prediction, but could be anything\n",
        "    depth = 6,                          # depth, paper recommended 6\n",
        "    heads = 8,                          # heads, paper recommends 8\n",
        "    attn_dropout = 0.1,                 # post-attention dropout\n",
        "    ff_dropout = 0.1                    # feed forward dropout\n",
        ")\n",
        "\n",
        "x_categ = torch.randint(0, 5, (1, 5))     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
        "x_numer = torch.randn(1, 10)              # numerical value"
      ],
      "metadata": {
        "id": "iFiY7sl2tN7Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_categ, x_categ.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5omvgkPV-E_",
        "outputId": "a3c796a2-88ba-4026-ee90-6c8606b387bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 3, 2, 1, 0]]) torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_numer, x_numer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0pQEhpV_oM",
        "outputId": "4b02b436-e6c8-4788-bd45-5ad506156a9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.1432,  1.2580,  1.2238,  1.8587, -0.1827, -0.2536, -2.2995,  0.5214,\n",
            "          1.6646,  0.3972]]) torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(x_categ, x_numer)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCl_-QEwWAxo",
        "outputId": "26ff1e91-8d44-4f3b-f8fb-2e8ce5c50bef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1088]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred, attn = model(x_categ, x_numer, return_attn = True)\n",
        "attn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sA4IcCpWbMH",
        "outputId": "22390dfa-8f98-4c02-f2e3-d833161ec579"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 8, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQjNYOvPWQ0Y"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}